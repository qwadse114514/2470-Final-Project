{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SI2TCtst_TP2"
      },
      "source": [
        "# CSCI 2470 Final Project"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Dependencies"
      ],
      "metadata": {
        "id": "qbLmil-2ahpe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install gymnasium\n",
        "# !pip install pysr"
      ],
      "metadata": {
        "id": "2eZsNEvYadaY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b167c22-c0fc-4510-d1eb-421b550c38b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gymnasium\n",
            "  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.12.2)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
            "Downloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: farama-notifications, gymnasium\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-1.0.0\n",
            "Collecting pysr\n",
            "  Downloading pysr-1.1.0-py3-none-any.whl.metadata (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pysr) (1.13.1)\n",
            "Requirement already satisfied: pandas<3.0.0,>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pysr) (2.2.2)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from pysr) (1.26.4)\n",
            "Requirement already satisfied: scikit_learn<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pysr) (1.5.2)\n",
            "Collecting juliacall==0.9.23 (from pysr)\n",
            "  Downloading juliacall-0.9.23-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: click<9.0.0,>=7.0.0 in /usr/local/lib/python3.10/dist-packages (from pysr) (8.1.7)\n",
            "Requirement already satisfied: setuptools>=50.0.0 in /usr/local/lib/python3.10/dist-packages (from pysr) (75.1.0)\n",
            "Collecting juliapkg~=0.1.8 (from juliacall==0.9.23->pysr)\n",
            "  Downloading juliapkg-0.1.15-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=0.21.0->pysr) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=0.21.0->pysr) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=0.21.0->pysr) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn<2.0.0,>=1.0.0->pysr) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn<2.0.0,>=1.0.0->pysr) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn<2.0.0,>=1.0.0->pysr) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy<2.0.0,>=1.0.0->pysr) (1.3.0)\n",
            "Collecting semver~=3.0 (from juliapkg~=0.1.8->juliacall==0.9.23->pysr)\n",
            "  Downloading semver-3.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=0.21.0->pysr) (1.16.0)\n",
            "Downloading pysr-1.1.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.6/91.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading juliacall-0.9.23-py3-none-any.whl (12 kB)\n",
            "Downloading juliapkg-0.1.15-py3-none-any.whl (16 kB)\n",
            "Downloading semver-3.0.2-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: semver, juliapkg, juliacall, pysr\n",
            "Successfully installed juliacall-0.9.23 juliapkg-0.1.15 pysr-1.1.0 semver-3.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Global Parameters"
      ],
      "metadata": {
        "id": "pPFhwvO8vkCH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is a limit on how many points an environment remembers, and a limit on the places where the agent can query `{0,...,100}`"
      ],
      "metadata": {
        "id": "aN8BFI1Gv2QA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_point_count = 10\n",
        "num_actions = 2*max_point_count # half of action space is for answering"
      ],
      "metadata": {
        "id": "cIPogIRFvnTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLxQcLwa_TP4"
      },
      "source": [
        "## Generate Terms\n",
        "\n",
        "Let's use `c` to denote constants (e.g., `1` and `2` and `π` and `e`) and `x` to denote variables/parameters (e.g., `x`).\n",
        "\n",
        "A term/expression `t` is one of the following\n",
        "\n",
        "* `c`, constants,\n",
        "* `x`, variable reference,\n",
        "* `sin(t)`\n",
        "* `t + t`\n",
        "* `t - t`\n",
        "* `t × t`\n",
        "\n",
        "*Note: we denote terms/expressions with `t` rather than `e` because people might misread `e` as the Euler's number.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJ7FrTIR_TP5"
      },
      "source": [
        "### Generate Terms with an Expected Size\n",
        "\n",
        "We can size terms by the following function:\n",
        "\n",
        "```\n",
        "size(c)       = 1\n",
        "size(x)       = 1\n",
        "size(⊖ t)     = 1 + size t\n",
        "size(t1 ⊕ t2) = 1 + size t1 + size t2\n",
        "```\n",
        "\n",
        "We want to make sure that the expected size of a random term `S = E[size(t)]` is bound\n",
        "\n",
        "So we need to solve the following\n",
        "\n",
        "|                 constraints                  |\n",
        "| :------------------------------------------: |\n",
        "| S = p₀ × 1 + p₁ × (1 + S) + p₂ × (1 + 2 × S) |\n",
        "|               p₀ + p₁ + p₂ = 1               |\n",
        "|           pᵢ ≥ 0, ∀ i ∈ {1, 2, 3}            |\n",
        "\n",
        "which reduces to\n",
        "\n",
        "|        constraints         |\n",
        "| :------------------------: |\n",
        "|  1/S ​≤ p₀ ​≤ (1 + 1/S) / 2  |\n",
        "|      p₁ = 1-2×p₀+1/S​​       |\n",
        "|       p₂ = p₀ - 1/S        |\n",
        "\n",
        "This system is under-constraint. So we will pick `p₀` uniformly randomly."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### More Considerations\n",
        "\n",
        "We further adjust our generator in the following ways:\n",
        "\n",
        "* We generate constants from the standard normal distribution.\n",
        "* We round generated constants to two digits for the sake of readability.\n",
        "* We use `sympy.simplify` to normalize the generated term to avoid generating, for example, both `x * x` and `x²`."
      ],
      "metadata": {
        "id": "M76nPcXLDLy2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYd8ze2O_TP6"
      },
      "outputs": [],
      "source": [
        "import sympy as sp\n",
        "import numpy as np\n",
        "\n",
        "the_x = sp.symbols(\"x\")\n",
        "\n",
        "def make_term(expected_size = 2, max_depth = 5):\n",
        "    assert expected_size >= 1, f\"the expected size must be at least 1, given {expected_size}\"\n",
        "    assert max_depth >= 1, f\"the expected size must be at least 1, given {max_depth}\"\n",
        "\n",
        "    import random\n",
        "    term0_maker = lambda depth: np.random.choice([\n",
        "        lambda: round(np.random.normal(), ndigits=2),\n",
        "        lambda: the_x # We want x to appear more often than numbers\n",
        "    ], p = [0.2, 0.8])()\n",
        "    term1_maker = lambda depth: np.random.choice([\n",
        "        lambda: sp.sin(new_term(depth)),\n",
        "        # lambda: sp.exp(new_term(depth)),\n",
        "    ])()\n",
        "    term2_maker = lambda depth: np.random.choice([\n",
        "        lambda: new_term(depth) + new_term(depth),\n",
        "        lambda: new_term(depth) - new_term(depth),\n",
        "        lambda: new_term(depth) * new_term(depth),\n",
        "    ])()\n",
        "\n",
        "    S = expected_size\n",
        "    p0_lower = 1/S\n",
        "    p0_upper = (1 + 1/S) / 2\n",
        "\n",
        "    def new_term(depth):\n",
        "        if depth >= max_depth:\n",
        "            maker = term0_maker\n",
        "        else:\n",
        "            p0 = np.random.uniform(p0_lower, p0_upper)\n",
        "            p1 = 1 - 2*p0 + 1/S\n",
        "            p2 = p0 - 1/S\n",
        "            assert p0 >= 0, f\"p0 is {p0}\"\n",
        "            assert p1 >= 0, f\"p1 is {p1}\"\n",
        "            assert p2 >= 0, f\"p2 is {p2}\"\n",
        "            assert 0.9 <= p0 + p1 + p2 <= 1.1, f\"p0, p1, p2 is {(p0, p1, p2)}; They sum up to {p0 + p1 + p2}\"\n",
        "\n",
        "            maker = random.choices(\n",
        "                [\n",
        "                    term0_maker,\n",
        "                    term1_maker,\n",
        "                    term2_maker\n",
        "                ],\n",
        "                weights=[ p0, p1, p2 ],\n",
        "                k=1\n",
        "            )[0]\n",
        "        return maker(depth + 1)\n",
        "    return new_term(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test the Generator"
      ],
      "metadata": {
        "id": "kV3mQYNwD_DW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 39
        },
        "id": "yzoLmjhw_TP8",
        "outputId": "a173ec99-c9cd-40ae-d193-abf7857da9b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "x"
            ],
            "text/latex": "$\\displaystyle x$"
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "make_term(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate 20 terms"
      ],
      "metadata": {
        "id": "tLBz_yzGEA3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[\n",
        "    make_term(3) for _ in range(20)\n",
        "]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgJUe_qaECPQ",
        "outputId": "f752954a-3524-42b8-9628-3018e2fd1d0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[sin(sin(x)),\n",
              " x*sin(x),\n",
              " x,\n",
              " x,\n",
              " sin(x),\n",
              " -0.21,\n",
              " -0.362473457456449,\n",
              " -sin(x),\n",
              " x,\n",
              " -2.13,\n",
              " x - sin(x - sin(x)),\n",
              " 0.307960934385481,\n",
              " 0.87,\n",
              " 2*x,\n",
              " x,\n",
              " 1.29,\n",
              " x + sin(x),\n",
              " sin(sin(sin(x))),\n",
              " x,\n",
              " sin(x)]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build a set of terms"
      ],
      "metadata": {
        "id": "xQ1SsjTD-4ta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "the_terms = []\n",
        "\n",
        "the_terms_strs = set()\n",
        "while len(the_terms) < 100:\n",
        "    term = make_term(3)\n",
        "    term_str = str(term)\n",
        "    if term_str not in the_terms_strs:\n",
        "        the_terms_strs.add(term_str)\n",
        "        the_terms.append(term)\n",
        "np.random.choice(the_terms, size = 5)"
      ],
      "metadata": {
        "id": "8F0dZcrg-11A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b173c02-5815-4e2d-bc3a-59f0d2991945"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([sin(x + sin(x)), 0, x + 1.89, -0.0499375858243268, x + 0.88],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Answer Model (PySR-based)\n",
        "\n",
        "is provided by PySR."
      ],
      "metadata": {
        "id": "iuRPStebjduM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def symbolic_regression(x, y):\n",
        "\n",
        "    # suppress some warning messages\n",
        "    import warnings\n",
        "    warnings.filterwarnings(\n",
        "        \"ignore\",\n",
        "        message=\"Note: it looks like you are running in Jupyter.*\"\n",
        "    )\n",
        "\n",
        "    from pysr import PySRRegressor\n",
        "\n",
        "    model = PySRRegressor(\n",
        "        verbosity=0,\n",
        "        maxsize=20,\n",
        "        niterations=5,  # < Increase me for better results\n",
        "        binary_operators=[\"+\", \"*\"],\n",
        "        unary_operators=[\n",
        "            \"cos\",\n",
        "            \"exp\",\n",
        "            \"sin\",\n",
        "        ],\n",
        "        elementwise_loss=\"loss(prediction, target) = (prediction - target)^2\",\n",
        "        # ^ Custom loss function (julia syntax)\n",
        "    )\n",
        "\n",
        "    model.fit(x[..., np.newaxis], y)\n",
        "    return model.sympy()"
      ],
      "metadata": {
        "id": "YjbOxp_qjiUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example usage:"
      ],
      "metadata": {
        "id": "kXVPWrlijlbX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# x = 2 * np.random.randn(100)\n",
        "# y = 2.5382 * np.cos(x) + x ** 2 - 0.5\n",
        "# e = symbolic_regression(x, y)\n",
        "# print(e)\n",
        "# numerical_func = sp.lambdify('x0', e, modules=[\"numpy\"])\n",
        "# numerical_func(0)"
      ],
      "metadata": {
        "id": "ufPazmuMjkEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Environment\n",
        "\n",
        "In our case:\n",
        "\n",
        "* The **observation** is a list of 2D points.\n",
        "* The **state** includes the observation and the underlying function.\n",
        "* The **action** is either \"answer\" or \"query\" at a certain place.\n",
        "\n",
        "The following `gym` definition (adapted from [an example from gymnasium's official document](https://gymnasium.farama.org/introduction/create_custom_env/)) makes these two points explicit."
      ],
      "metadata": {
        "id": "onrZlcV8Ecuj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute the reward by L2"
      ],
      "metadata": {
        "id": "Zx9wRKxHlhAA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### L2"
      ],
      "metadata": {
        "id": "8N-73kGsnmF9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def L2_distance_uniform(f1, f2, a=-1, b=1, N=1000):\n",
        "    \"\"\"\n",
        "    Approximate the L2 distance between two sympy expressions expr1 and expr2\n",
        "    over a bounded interval [a, b] using Monte Carlo uniform sampling.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    var : sympy.Symbol, optional\n",
        "        The variable in the expressions. Defaults to sympy.Symbol(\"x\").\n",
        "    a : float, optional\n",
        "        Lower bound of the interval for sampling. Defaults to -1.\n",
        "    b : float, optional\n",
        "        Upper bound of the interval for sampling. Defaults to 1.\n",
        "    N : int, optional\n",
        "        Number of sample points to use for the approximation. Default is 1000.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    float\n",
        "        Approximate L2 distance between the two functions over [a, b].\n",
        "    \"\"\"\n",
        "    if a >= b:\n",
        "        raise ValueError(\"Lower bound 'a' must be less than upper bound 'b'.\")\n",
        "\n",
        "    # Define a uniform sampler over [a, b]\n",
        "    sampler = lambda size: np.random.uniform(a, b, size)\n",
        "\n",
        "    # Sample points\n",
        "    X = sampler(N)  # shape: (N,)\n",
        "\n",
        "    # Evaluate functions at sampled points\n",
        "    y1 = f1(X)\n",
        "    y2 = f2(X)\n",
        "\n",
        "    # Compute mean square difference\n",
        "    msd = np.mean((y1 - y2) ** 2)\n",
        "\n",
        "    # Scale by the interval length for accurate L2 norm approximation\n",
        "    interval_length = b - a\n",
        "    L2_distance = np.sqrt(msd) * np.sqrt(interval_length)\n",
        "\n",
        "    return L2_distance"
      ],
      "metadata": {
        "id": "TglM8wjclgjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L2_distance_uniform(lambda x: x, lambda x: x + 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cKeJ6einX_p",
        "outputId": "8c418681-aac3-48e3-ad16-0c8b93c0a1e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.4142135623730951"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "L2_distance_uniform(lambda x: x, lambda x: x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qk-UvH50ngIs",
        "outputId": "f19611bb-8928-4d53-a8c0-c702d85260ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "L2_distance_uniform(lambda x: x, lambda x: np.sin(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXaOOprXnuCB",
        "outputId": "efcb9abe-e948-4c9c-eb6a-5c91a679d611"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08453134990477468"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Reward\n",
        "\n",
        "The distance is in `[0, +inf)`. We want to make sure the reward is in `[0, 1]` so we can give reward `0` when the model times out, and reward `1` when the answer is perfect.\n",
        "\n",
        "We tried `1 / (1 + distance)` but this reward is too permissive for not exactly right answer. The current reward is `1 / exp(distance)`."
      ],
      "metadata": {
        "id": "PfF3x1umnoUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_reward(expr, known_points):\n",
        "\n",
        "    # the true answer\n",
        "    f1 = sp.lambdify(the_x, expr)\n",
        "\n",
        "    # the guessed answer\n",
        "    e = symbolic_regression(\n",
        "        np.array([x for x, y in known_points]),\n",
        "        np.array([y for x, y in known_points])\n",
        "    )\n",
        "    f2 = sp.lambdify('x0', e, modules=[\"numpy\"])\n",
        "\n",
        "    d = L2_distance_uniform(f1, f2)\n",
        "\n",
        "    # map distance [0, +inf) to [0, 1]\n",
        "    return 1 / (1 + d), e\n",
        "    # return 1 / np.exp(d), e"
      ],
      "metadata": {
        "id": "e1Mt-1AgmRvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute_reward(the_x, [(0, 0), (1, 1), (2, 2)])"
      ],
      "metadata": {
        "id": "YNTa50C7oDC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute_reward(the_x, [(0, 1), (1, 2), (2, 3)])"
      ],
      "metadata": {
        "id": "9A23h2nXwl2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encode States"
      ],
      "metadata": {
        "id": "E8YM6HDsrnqd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A state is a list of 2d points; The list length is not greater than max_point_count.\n",
        "We want to convert it to an array of shape (max_point_count, 2) by filling in zeros."
      ],
      "metadata": {
        "id": "EEdUJocWszRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def encode_state(state):\n",
        "    assert len(state) <= max_point_count, f\"len(state) is {len(state)}, which exceeds the limit {max_point_count}\"\n",
        "\n",
        "    state = tf.convert_to_tensor(state, dtype=float)\n",
        "\n",
        "    # add noise to avoid keep querying the same thing\n",
        "    # state += tf.random.normal(shape=state.shape, stddev=0.1)\n",
        "\n",
        "    target_shape = (max_point_count, 2)\n",
        "\n",
        "    # Calculate the padding\n",
        "    pad_rows = target_shape[0] - tf.shape(state)[0]\n",
        "    padding = [[0, pad_rows], [0, 0]]  # Pad rows only, no padding for columns\n",
        "\n",
        "    # Pad the state\n",
        "    return tf.pad(state, padding)"
      ],
      "metadata": {
        "id": "m2oQkfzZswHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encode_state([\n",
        "    (1, 2),\n",
        "    (3, 4),\n",
        "])[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EH-ENMMFs6BV",
        "outputId": "99bf4d5d-8351-4107-8c64-f48ff52202cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10, 2), dtype=float32, numpy=\n",
              "array([[1., 2.],\n",
              "       [3., 4.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Environment `gym` Definition"
      ],
      "metadata": {
        "id": "iGBr5qDbbN1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional\n",
        "import gymnasium as gym\n",
        "\n",
        "class MyEnv(gym.Env):\n",
        "\n",
        "    def __init__(self, term = None):\n",
        "        from collections import defaultdict\n",
        "\n",
        "        self.observation_space = gym.spaces.Sequence(\n",
        "              gym.spaces.Box(\n",
        "              low=float('-inf'), high=float('inf'),\n",
        "              shape=(2,),\n",
        "              dtype=np.float32\n",
        "          )\n",
        "        )\n",
        "\n",
        "        self.action_space = gym.spaces.Discrete(num_actions)\n",
        "\n",
        "        if term is None:\n",
        "            self.term = make_term(3)\n",
        "        else:\n",
        "            self.term = term\n",
        "\n",
        "        self.time = 0\n",
        "        self.known_points = None\n",
        "\n",
        "    def _query(self, new_x):\n",
        "        new_x += np.random.randn()\n",
        "        new_y = sp.lambdify(the_x, self.term)(new_x)\n",
        "\n",
        "        self.time += 1\n",
        "        self.known_points.append(np.array([new_x, new_y], dtype=float))\n",
        "\n",
        "    def reset(self, seed: Optional[int] = None, options: Optional[dict] = None):\n",
        "        # We need the following line to seed self.np_random\n",
        "        super().reset(seed=seed)\n",
        "\n",
        "        if options is not None and 'term' in options:\n",
        "            self.term = options['term']\n",
        "        else:\n",
        "            self.term = np.random.choice(the_terms)\n",
        "\n",
        "        self.time = 0\n",
        "        self.known_points = []\n",
        "\n",
        "        self._query(0)\n",
        "\n",
        "        observation = tuple(self.known_points)\n",
        "        info = { \"term\": self.term }\n",
        "\n",
        "        return observation, info\n",
        "\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        if action >= max_point_count:\n",
        "            terminated = True\n",
        "            reward, e = compute_reward(self.term, self.known_points)\n",
        "            action = f\"answered {e}\"\n",
        "        elif self.time + 1 < max_point_count:\n",
        "            self._query(action)\n",
        "            terminated = False\n",
        "            reward = - float(1/max_point_count) * (1 + self.time)\n",
        "            action = f\"queried {action}\"\n",
        "        else:\n",
        "            self.time += 1\n",
        "            terminated = True\n",
        "            reward = - float(1/max_point_count) * (1 + self.time)\n",
        "            action = f\"timeout\"\n",
        "\n",
        "        observation = tuple(self.known_points)\n",
        "        truncated = False\n",
        "        info = { \"action\": action }\n",
        "\n",
        "        return observation, reward, terminated, truncated, info\n",
        "\n",
        "gym.register(\n",
        "    id=\"gymnasium_env/LittleScientist\",\n",
        "    entry_point=MyEnv,\n",
        ")"
      ],
      "metadata": {
        "id": "DjotzjzmRsRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test the Environment"
      ],
      "metadata": {
        "id": "RK3b2lCtbYqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make('gymnasium_env/LittleScientist')\n",
        "env.observation_space"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7lIUcfubYWv",
        "outputId": "82276019-2ad6-4be9-e67a-33e79880224d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequence(Box(-inf, inf, (2,), float32), stack=False)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.action_space"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oExUTB-CdmqS",
        "outputId": "cf8f7525-d218-4441-ce0f-7697b8a1b3f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discrete(20)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.reset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgK2OyaydqG4",
        "outputId": "dd6d07ff-fd78-46ce-b578-d74f5113afdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gymnasium/utils/passive_env_checker.py:158: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
            "  logger.warn(f\"{pre} is not within the observation space.\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([-0.33186597, -1.04      ]),), {'term': -1.04})"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.action_space.sample()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMLj2DLCd-w_",
        "outputId": "f65d3e93-6ffd-44d7-d2c4-e24f95623017"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.observation_space.sample()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9bRPkG8w8fb",
        "outputId": "01a367e8-1c32-4e3f-9fb8-dc1315992e9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-1.7134843, -0.8774723], dtype=float32),\n",
              " array([ 0.8758127, -1.503819 ], dtype=float32),\n",
              " array([-0.65272534, -0.17953993], dtype=float32),\n",
              " array([-0.3111068 , -0.11345543], dtype=float32),\n",
              " array([-0.09398746, -1.1925148 ], dtype=float32),\n",
              " array([ 1.0039654 , -0.31497705], dtype=float32),\n",
              " array([1.4074302, 1.2093539], dtype=float32),\n",
              " array([-0.2551157,  1.1390036], dtype=float32),\n",
              " array([-3.142295  ,  0.97203666], dtype=float32),\n",
              " array([0.81900615, 1.3895038 ], dtype=float32),\n",
              " array([-0.41725042, -0.31643704], dtype=float32),\n",
              " array([ 0.8656851 , -0.33373335], dtype=float32),\n",
              " array([1.3987029, 0.358785 ], dtype=float32),\n",
              " array([0.42660344, 0.05870843], dtype=float32),\n",
              " array([-1.6319885 , -0.86893797], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gym.make('gymnasium_env/LittleScientist').reset(options={'term': the_x})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LxB90rKGW9V",
        "outputId": "34939a8d-5fb0-4f9a-9898-fb67e0c8468e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([-0.43751824, -0.43751824]),), {'term': x})"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gym.make('gymnasium_env/LittleScientist').reset(options={'term': the_x})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzcWKO3jGbK8",
        "outputId": "5a2f86c7-cecb-4f16-981f-15b80f1db9ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([1.21716053, 1.21716053]),), {'term': x})"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model(s)\n",
        "\n",
        "The model is a dictionary from action to reward.\n",
        "\n",
        "The action space is 100, where 0 is giving an answer, and all other points mean querying. Making `0` the query action is fine because the env always queries `0` when reset."
      ],
      "metadata": {
        "id": "a2b4SCZ8Rsxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras as keras\n",
        "import tensorflow.keras.layers as layers\n",
        "\n",
        "def make_model():\n",
        "    # Network defined by the Deepmind paper\n",
        "    return keras.Sequential(\n",
        "        [\n",
        "            layers.Input((max_point_count, 2)),\n",
        "            layers.Flatten(),\n",
        "            layers.Dense(512, activation=\"relu\"),\n",
        "            layers.Dense(256, activation=\"relu\"),\n",
        "            layers.Dense(num_actions, activation=\"linear\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "# The first model makes the predictions for Q-values which are used to\n",
        "# make a action.\n",
        "model = make_model()\n",
        "# Build a target model for the prediction of future rewards.\n",
        "# The weights of a target model get updated every update_target_network steps thus when the\n",
        "# loss between the Q-values is calculated the target Q-value is stable.\n",
        "model_target = make_model()"
      ],
      "metadata": {
        "id": "IM_-a-WbrTcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example Episode(s) Before Training"
      ],
      "metadata": {
        "id": "UFU3aNpPBMpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_episode(model, term=None):\n",
        "    state, info = env.reset(options = term and { 'term': term })\n",
        "    # print(\"info\", info)\n",
        "    term = info['term']\n",
        "    print(f\"The true answer is {term}\")\n",
        "\n",
        "    done = False\n",
        "    for _ in range(50):\n",
        "        action = model.predict(np.array([encode_state(state)]), verbose=0)[0]\n",
        "        action = np.argmax(action)\n",
        "        state, reward, done, _, info = env.step(action)\n",
        "        print(info['action'], reward)\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "make_episode(model, term=the_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0LybqzrBPrB",
        "outputId": "68260a61-6a7a-413a-a225-339262d2a8a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The true answer is x\n",
            "queried 5 -0.30000000000000004\n",
            "answered x0 - 1.3425961e-8 0.9999999810128243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "\n",
        "This section is heavily inspired by\n",
        "\n",
        "https://keras.io/examples/rl/deep_q_network_breakout/\n",
        "\n",
        "We changed many places to fit our setting."
      ],
      "metadata": {
        "id": "rVsVKkRrp-UW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set Up"
      ],
      "metadata": {
        "id": "oCg1LxborjrV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Configuration parameters for the whole setup\n",
        "gamma = 0.99  # Discount factor for past rewards\n",
        "epsilon = 0.2\n",
        "# epsilon = 1.0  # Epsilon greedy parameter\n",
        "# epsilon_min = 0.1  # Minimum epsilon greedy parameter\n",
        "# epsilon_max = 1.0  # Maximum epsilon greedy parameter\n",
        "# epsilon_interval = (\n",
        "#     epsilon_max - epsilon_min\n",
        "# )  # Rate at which to reduce chance of random action being taken\n",
        "batch_size = 32  # Size of batch taken from replay buffer\n",
        "max_steps_per_episode = 50\n",
        "max_episodes = 20  # Limit training episodes, will run until solved if smaller than 1\n",
        "\n",
        "env = gym.make('gymnasium_env/LittleScientist')\n",
        "\n",
        "# Experience replay buffers\n",
        "action_history = []\n",
        "state_history = []\n",
        "state_next_history = []\n",
        "rewards_history = []\n",
        "done_history = []\n",
        "episode_reward_history = []\n",
        "running_reward = 0\n",
        "episode_count = 0\n",
        "frame_count = 0\n",
        "# Maximum replay length\n",
        "max_memory_length = 1000\n",
        "# Train the model after 4 actions\n",
        "update_after_actions = 4\n",
        "# How often to update the target network\n",
        "update_target_network = 200\n",
        "# Using huber loss for stability\n",
        "loss_function = keras.losses.Huber()"
      ],
      "metadata": {
        "id": "jPbpyQHSqFuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Training Loop"
      ],
      "metadata": {
        "id": "xBMs25zixrI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.Adam()\n",
        "\n",
        "while True:\n",
        "    observation, _ = env.reset()\n",
        "    state = np.array(observation)\n",
        "    episode_reward = 0\n",
        "\n",
        "    for timestep in range(1, max_steps_per_episode):\n",
        "        frame_count += 1\n",
        "\n",
        "        # Use epsilon-greedy for exploration\n",
        "        if epsilon > np.random.rand(1)[0]:\n",
        "            # Take random action\n",
        "            action = np.random.choice(num_actions)\n",
        "        else:\n",
        "            # Predict action Q-values\n",
        "            # From environment state\n",
        "            state_tensor = keras.ops.convert_to_tensor(encode_state(state))\n",
        "            state_tensor = keras.ops.expand_dims(state_tensor, 0)\n",
        "            action_probs = model(state_tensor, training=False)\n",
        "            # Take best action\n",
        "            action = keras.ops.argmax(action_probs[0]).numpy()\n",
        "\n",
        "        # Apply the sampled action in our environment\n",
        "        state_next, reward, done, _, _ = env.step(action)\n",
        "        state_next = np.array(state_next)\n",
        "\n",
        "        episode_reward += reward\n",
        "\n",
        "        # Save actions and states in replay buffer\n",
        "        action_history.append(action)\n",
        "        state_history.append(state)\n",
        "        state_next_history.append(state_next)\n",
        "        done_history.append(done)\n",
        "        rewards_history.append(reward)\n",
        "        state = state_next\n",
        "\n",
        "        # Update every fourth frame and once batch size is over 32\n",
        "        if frame_count % update_after_actions == 0 and len(done_history) > batch_size:\n",
        "            # Get indices of samples for replay buffers\n",
        "            indices = np.random.choice(range(len(done_history)), size=batch_size)\n",
        "\n",
        "            # Using list comprehension to sample from replay buffer\n",
        "            state_sample = np.array([encode_state(state_history[i]) for i in indices])\n",
        "            state_next_sample = np.array([encode_state(state_next_history[i]) for i in indices])\n",
        "            rewards_sample = [rewards_history[i] for i in indices]\n",
        "            action_sample = [action_history[i] for i in indices]\n",
        "            done_sample = keras.ops.convert_to_tensor(\n",
        "                [float(done_history[i]) for i in indices]\n",
        "            )\n",
        "\n",
        "            # Build the updated Q-values for the sampled future states\n",
        "            # Use the target model for stability\n",
        "            future_rewards = model_target.predict(state_next_sample, verbose=0)\n",
        "            # Q value = reward + discount factor * expected future reward\n",
        "            updated_q_values = rewards_sample + gamma * keras.ops.amax(\n",
        "                future_rewards, axis=1\n",
        "            )\n",
        "\n",
        "            # If final frame set the last value to -1\n",
        "            updated_q_values = updated_q_values * (1 - done_sample) - done_sample\n",
        "\n",
        "            # Create a mask so we only calculate loss on the updated Q-values\n",
        "            masks = keras.ops.one_hot(action_sample, num_actions)\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "                # Train the model on the states and updated Q-values\n",
        "                q_values = model(state_sample)\n",
        "\n",
        "                # Apply the masks to the Q-values to get the Q-value for action taken\n",
        "                q_action = keras.ops.sum(keras.ops.multiply(q_values, masks), axis=1)\n",
        "                # Calculate loss between new Q-value and old Q-value\n",
        "                loss = loss_function(updated_q_values, q_action)\n",
        "\n",
        "            # Backpropagation\n",
        "            grads = tape.gradient(loss, model.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "        if frame_count % update_target_network == 0:\n",
        "            # update the the target network with new weights\n",
        "            model_target.set_weights(model.get_weights())\n",
        "            # Log details\n",
        "            template = \"running reward: {:.2f} at episode {}, frame count {}\"\n",
        "            print(template.format(running_reward, episode_count, frame_count))\n",
        "\n",
        "        # Limit the state and reward history\n",
        "        if len(rewards_history) > max_memory_length:\n",
        "            del rewards_history[:1]\n",
        "            del state_history[:1]\n",
        "            del state_next_history[:1]\n",
        "            del action_history[:1]\n",
        "            del done_history[:1]\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    # Update running reward to check condition for solving\n",
        "    episode_reward_history.append(episode_reward)\n",
        "    if len(episode_reward_history) > 100:\n",
        "        del episode_reward_history[:1]\n",
        "    running_reward = np.mean(episode_reward_history)\n",
        "\n",
        "    episode_count += 1\n",
        "\n",
        "    if running_reward > 0 and episode_count >= 10:  # Condition to consider the task solved\n",
        "        print(\"Solved at episode {}!\".format(episode_count))\n",
        "        break\n",
        "\n",
        "    if (\n",
        "        max_episodes > 0 and episode_count >= max_episodes\n",
        "    ):  # Maximum number of episodes reached\n",
        "        print(\"Stopped at episode {}!\".format(episode_count))\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzrG7fVaqW_F",
        "outputId": "5f1879a3-7682-44a5-c0a3-739e8bf88a00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gymnasium/utils/passive_env_checker.py:158: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
            "  logger.warn(f\"{pre} is not within the observation space.\")\n",
            "/usr/local/lib/python3.10/dist-packages/gymnasium/utils/passive_env_checker.py:158: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
            "  logger.warn(f\"{pre} is not within the observation space.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solved at episode 10!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example Episode(s) After Training"
      ],
      "metadata": {
        "id": "XN2lMgP9zVO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "make_episode(model, term=the_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yf6TcM-zI0FL",
        "outputId": "43318f87-7ed5-46ca-a77e-6df26df72879"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The true answer is x\n",
            "queried 5 -0.30000000000000004\n",
            "answered x0 - 1.1221864e-8 0.9999999841298879\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "make_episode(model, term=the_x*the_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxOyd4IeNNjH",
        "outputId": "9c589edb-bdfb-425b-a1d4-159b7085444f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The true answer is x**2\n",
            "queried 7 -0.30000000000000004\n",
            "answered x0*x0 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "make_episode(model, term=the_x*sp.sin(the_x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ewSNz5bNRsu",
        "outputId": "3e809bcb-d861-45cb-9308-8876908c46c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The true answer is x*sin(x)\n",
            "queried 7 -0.30000000000000004\n",
            "answered x0*sin(x0) 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Testing"
      ],
      "metadata": {
        "id": "vyIFI10s_dx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_functions = [\n",
        "    (\"Linear Function\", the_x + 1),\n",
        "    (\"Quadratic Function\", the_x**2),\n",
        "    (\"Sine Function\", sp.sin(the_x)),\n",
        "    (\"Polynomial Function\", 2*the_x**2+the_x-1),\n",
        "    (\"combinition Function\", sp.sin(the_x**2)),\n",
        "]\n"
      ],
      "metadata": {
        "id": "LDcKgT08RjcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_functions[0][0])\n",
        "make_episode(model, term=test_functions[0][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBdYCTM5RqZ9",
        "outputId": "494fc7b2-3073-4f4d-aac6-e9fada0573f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Function\n",
            "The true answer is x + 1\n",
            "queried 5 -0.30000000000000004\n",
            "answered x0 + 1.0 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_functions[1][0])\n",
        "make_episode(model, term=test_functions[1][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2i5VaBQRwpD",
        "outputId": "46f02db5-207e-4ea0-bdc1-8c4cb0575c9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quadratic Function\n",
            "The true answer is x**2\n",
            "queried 7 -0.30000000000000004\n",
            "answered x0*x0 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_functions[2][0])\n",
        "make_episode(model, term=test_functions[2][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-0qiAq9RxYi",
        "outputId": "ee5c775f-c871-4eb6-ce78-6d34b80d1614"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sine Function\n",
            "The true answer is sin(x)\n",
            "queried 5 -0.30000000000000004\n",
            "answered x0*1.854735e-8 + sin(x0) 0.9999999850749357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_functions[3][0])\n",
        "make_episode(model, term=test_functions[3][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JjLsfiHRyIn",
        "outputId": "ec349f11-eb34-4550-a30a-9974c249fdcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Polynomial Function\n",
            "The true answer is 2*x**2 + x - 1\n",
            "queried 7 -0.30000000000000004\n",
            "answered x0*(x0 + x0) + x0 - 1.0 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_functions[4][0])\n",
        "make_episode(model, term=test_functions[4][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23RA9DL_RzHX",
        "outputId": "39143831-968f-4f08-b7a6-8b1f9544513e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "combinition Function\n",
            "The true answer is sin(x**2)\n",
            "queried 5 -0.30000000000000004\n",
            "answered sin(x0*x0) 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "\n",
        "* https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html\n",
        "* https://keras.io/examples/rl/deep_q_network_breakout/"
      ],
      "metadata": {
        "id": "86ODcfy_sUNr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## END"
      ],
      "metadata": {
        "id": "p8eKdopAsRuk"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "csci2470",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}